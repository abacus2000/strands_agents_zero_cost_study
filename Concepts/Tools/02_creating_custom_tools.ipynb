{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1dde00",
   "metadata": {},
   "source": [
    "# Tool Creation Examples\n",
    "\n",
    "From the docs \n",
    "\n",
    "\"\"\"\n",
    "Invocation State Compared To Other Approaches\n",
    "\n",
    "It's important to understand how invocation state compares to other approaches that impact tool execution:\n",
    "\n",
    "    Tool Parameters: Use for data that the LLM should reason about and provide based on the user's request. Examples include search queries, file paths, calculation inputs, or any data the agent needs to determine from context.\n",
    "\n",
    "    Invocation State: Use for context and configuration that should not appear in prompts but affects tool behavior. Best suited for parameters that can change between agent invocations. Examples include user IDs for personalization, session IDs, or user flags.\n",
    "\n",
    "    Class-based tools: Use for configuration that doesn't change between requests and requires initialization. Examples include API keys, database connection strings, service endpoints, or shared resources that need setup.\n",
    "\n",
    "\"\"\" [1] \n",
    "\n",
    "Bottom line up top:\n",
    "\n",
    "Tool parameters can be adjusting by add to the @tool() decorator, adding inputs inside the brackets. \n",
    "\n",
    "Tool parameters use invocation_state to get structured inputs; e.g. `agent(\"Get my fake profile data. This is a test.\", invocation_state={\"user_id\": \"user123\"})\n",
    "`\n",
    "\n",
    "Class based tools are tools that need a state that persists beyond a given execution, like a tool with a connection that needs to stay open. - there is nothing special about the class based connection with respect to the library so I am skipping the example breakout; this is more of are architecural approach using the standard __init__() to setup the class state, and decorating the class methods with @tool.\n",
    "\n",
    "[1] https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/custom-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import tool, Agent\n",
    "from strands.models import BedrockModel\n",
    "# the @tool decorator extracts information from your function's docstring to create the tool specification. \n",
    "#  The first paragraph becomes the tool's description, and the \"Args\" section provides parameter descriptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b30c5",
   "metadata": {},
   "source": [
    "# Overriding Tool Name, Description, and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45579125",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(name=\"get_weather\", description=\"Retrieves weather forecast for a specified location\")\n",
    "def weather_forecast(city: str, days: int = 3) -> str:\n",
    "    \"\"\"Implementation function for weather forecasting.\n",
    "\n",
    "    Args:\n",
    "        city: The name of the city\n",
    "        days: Number of days for the forecast\n",
    "    \"\"\"\n",
    "    return f\"Weather forecast for {city} for the next {days} days...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813f75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\n",
    "    inputSchema={\n",
    "        \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"shape\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"circle\", \"rectangle\"],\n",
    "                    \"description\": \"The shape type\"\n",
    "                },\n",
    "                \"radius\": {\"type\": \"number\", \"description\": \"Radius for circle\"},\n",
    "                \"width\": {\"type\": \"number\", \"description\": \"Width for rectangle\"},\n",
    "                \"height\": {\"type\": \"number\", \"description\": \"Height for rectangle\"}\n",
    "            },\n",
    "            \"required\": [\"shape\"]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "def calculate_area(shape: str, radius: float = None, width: float = None, height: float = None) -> float:\n",
    "    \"\"\"Calculate area of a shape.\"\"\"\n",
    "    if shape == \"circle\":\n",
    "        return 3.14159 * radius ** 2\n",
    "    elif shape == \"rectangle\":\n",
    "        return width * height\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd4d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[calculate_area]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: calculate_area\n",
      "The area of the circle with radius 5 is **78.54 square units** (rounded to two decimal places)."
     ]
    }
   ],
   "source": [
    "# testing the radius tool \n",
    "result = agent(\"Calculate the area of a circle with radius 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c530b",
   "metadata": {},
   "source": [
    "## Changing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef1c7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the weather tool \n",
    "\n",
    "def some_other_function(source_id):\n",
    "    return {'temperature': 5778, 'source': source_id}  \n",
    "\n",
    "@tool\n",
    "def sun_temperature_data(source_id: str) -> dict:\n",
    "    \"\"\"Fetch data from a specified source.\n",
    "\n",
    "    Args:\n",
    "        source_id: Identifier for the data source\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = some_other_function(source_id)\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"content\": [ {\n",
    "                \"json\": data,\n",
    "            }]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "             \"content\": [\n",
    "                {\"text\": f\"Error:{e}\"}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "bedrock_model2 = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent2 = Agent(\n",
    "    model=bedrock_model2,\n",
    "    tools=[sun_temperature_data]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea48d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: sun_temperature_data\n",
      "The latest data on sun temperature indicates a temperature of **5778 K** (Kelvin). This value represents the effective temperature of the Sun's photosphere, which is the visible surface layer we observe from Earth. \n",
      "\n",
      "This temperature is derived from the latest available measurements from the designated data source (`sun_temperature_latest`)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"The latest data on sun temperature indicates a temperature of **5778 K** (Kelvin). This value represents the effective temperature of the Sun's photosphere, which is the visible surface layer we observe from Earth. \\n\\nThis temperature is derived from the latest available measurements from the designated data source (`sun_temperature_latest`).\"}]}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={'sun_temperature_data': ToolMetrics(tool={'toolUseId': 'tooluse_F3reAqdbRnWfJd2ko02qYw', 'name': 'sun_temperature_data', 'input': {'source_id': 'sun_temperature_latest'}}, call_count=1, success_count=1, error_count=0, total_time=0.0006840229034423828)}, cycle_durations=[0.9228670597076416], agent_invocations=[AgentInvocation(cycles=[EventLoopCycleMetric(event_loop_cycle_id='8e935a6b-b297-4ab7-b7f8-0e61e7e31895', usage={'inputTokens': 928, 'outputTokens': 30, 'totalTokens': 958}), EventLoopCycleMetric(event_loop_cycle_id='cbf39846-3e32-4cec-8a43-3dfad31abc64', usage={'inputTokens': 998, 'outputTokens': 65, 'totalTokens': 1063})], usage={'inputTokens': 1926, 'outputTokens': 95, 'totalTokens': 2021})], traces=[<strands.telemetry.metrics.Trace object at 0x10a247bc0>, <strands.telemetry.metrics.Trace object at 0x108a3cc20>], accumulated_usage={'inputTokens': 1926, 'outputTokens': 95, 'totalTokens': 2021}, accumulated_metrics={'latencyMs': 1335}), state={}, interrupts=None, structured_output=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2(\"fetch the lateset data on sun temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1179c",
   "metadata": {},
   "source": [
    "## Async InvocationÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d50313",
   "metadata": {},
   "source": [
    "Strands Agents actually uses async calls by default without any asyncio implimentation. \n",
    "\n",
    "This is because the ConcurrentToolExecutor is the default tool executor. [1] \n",
    "Currently (today Jan 31st 2025) the documentation also indicates that you need special syntax but this is not the case. [2] \n",
    "\n",
    "We can use SequentialToolExecutor instead. \n",
    "\n",
    "== Ref ==\n",
    "\n",
    "[1] https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/executors/\n",
    "[2] https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/custom-tools/#async-invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156d7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.tools.executors import SequentialToolExecutor\n",
    "\n",
    "@tool\n",
    "async def call_api_sequential_1() -> str:\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Sequential API 1 call started at: {time.strftime('%H:%M:%S.%f', time.localtime(start_time))[:-3]}\")\n",
    "    \n",
    "    await asyncio.sleep(3)  # 3 second async call\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Sequential API 1 call completed at: {time.strftime('%H:%M:%S.%f', time.localtime(end_time))[:-3]}\")\n",
    "    print(f\"Sequential API 1 call duration: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return \"Sequential API 1 result\"\n",
    "\n",
    "@tool\n",
    "async def call_api_sequential_2() -> str:\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Sequential API 2 call started at: {time.strftime('%H:%M:%S.%f', time.localtime(start_time))[:-3]}\")\n",
    "    \n",
    "    await asyncio.sleep(4)  # 4 second async call\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Sequential API 2 call completed at: {time.strftime('%H:%M:%S.%f', time.localtime(end_time))[:-3]}\")\n",
    "    print(f\"Sequential API 2 call duration: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return \"Sequential API 2 result\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8393e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Agent invocation started at: 23:55:5\n",
      "\n",
      "Tool #1: call_api_sequential_1\n",
      "\n",
      "Tool #2: call_api_sequential_2\n",
      "Sequential API 1 call started at: 23:55:5\n",
      "Sequential API 1 call completed at: 23:56:0\n",
      "Sequential API 1 call duration: 3.00 seconds\n",
      "Sequential API 2 call started at: 23:56:0\n",
      "Sequential API 2 call completed at: 23:56:0\n",
      "Sequential API 2 call duration: 4.00 seconds\n",
      "Both APIs have been successfully called. Here are the results:\n",
      "\n",
      "1. Sequential API 1 returned: \"Sequential API 1 result\"\n",
      "2. Sequential API 2 returned: \"Sequential API 2 result\" \n",
      "\n",
      "Is there anything specific you'd like to do with these results or any further actions you'd like me to take?Sequential Agent invocation completed at: 23:56:0\n",
      "Sequential Total execution time: 8.68 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': 'Both APIs have been successfully called. Here are the results:\\n\\n1. Sequential API 1 returned: \"Sequential API 1 result\"\\n2. Sequential API 2 returned: \"Sequential API 2 result\" \\n\\nIs there anything specific you\\'d like to do with these results or any further actions you\\'d like me to take?'}]}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={'call_api_sequential_1': ToolMetrics(tool={'toolUseId': 'tooluse_F3EJH7VFQdGI7pF4nwUewQ', 'name': 'call_api_sequential_1', 'input': {}}, call_count=1, success_count=1, error_count=0, total_time=3.0033462047576904), 'call_api_sequential_2': ToolMetrics(tool={'toolUseId': 'tooluse_hUqKf0WbQ7WhOal_VzbLMA', 'name': 'call_api_sequential_2', 'input': {}}, call_count=1, success_count=1, error_count=0, total_time=4.002664089202881)}, cycle_durations=[0.7883310317993164], agent_invocations=[AgentInvocation(cycles=[EventLoopCycleMetric(event_loop_cycle_id='78479d6d-e582-4b25-9718-a242c70a94e2', usage={'inputTokens': 961, 'outputTokens': 34, 'totalTokens': 995}), EventLoopCycleMetric(event_loop_cycle_id='e276e1d7-ab39-4c86-961b-de4cfaefee87', usage={'inputTokens': 1051, 'outputTokens': 67, 'totalTokens': 1118})], usage={'inputTokens': 2012, 'outputTokens': 101, 'totalTokens': 2113})], traces=[<strands.telemetry.metrics.Trace object at 0x10e884e00>, <strands.telemetry.metrics.Trace object at 0x10d23fad0>], accumulated_usage={'inputTokens': 2012, 'outputTokens': 101, 'totalTokens': 2113}, accumulated_metrics={'latencyMs': 1125}), state={}, interrupts=None, structured_output=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "print(f\"Sequential Agent invocation started at: {time.strftime('%H:%M:%S.%f', time.localtime(start_time))[:-3]}\")\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tool_executor=SequentialToolExecutor(), \n",
    "    tools=[call_api_sequential_1, call_api_sequential_2],\n",
    "    system_prompt=\"You are a helpful assistant that can call multiple APIs. When asked to call APIs, call both API 1 and API 2.\"\n",
    ")\n",
    "\n",
    "result = agent(\"Can you call both of my APIs?\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Sequential Agent invocation completed at: {time.strftime('%H:%M:%S.%f', time.localtime(end_time))[:-3]}\")\n",
    "print(f\"Sequential Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42120199",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " Now lets we see the same thing but with the default and no special \n",
    " implimentation still sees async execution. \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6c708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Agent invocation started at: 23:59:3\n",
      "\n",
      "Tool #1: call_api_sequential_1\n",
      "\n",
      "Tool #2: call_api_sequential_2\n",
      "Sequential API 1 call started at: 23:59:3\n",
      "Sequential API 2 call started at: 23:59:3\n",
      "Sequential API 1 call completed at: 23:59:4\n",
      "Sequential API 1 call duration: 3.00 seconds\n",
      "Sequential API 2 call completed at: 23:59:4\n",
      "Sequential API 2 call duration: 4.00 seconds\n",
      "Both APIs have been successfully called:\n",
      "- Sequential API 1 result\n",
      "- Sequential API 2 result\n",
      "\n",
      "Is there anything specific you'd like to know or do next with these results?Normal Agent invocation completed at: 23:59:4\n",
      "Normal Total execution time: 5.56 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Normal Agent invocation started at: {time.strftime('%H:%M:%S.%f', time.localtime(start_time))[:-3]}\")\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[call_api_sequential_1, call_api_sequential_2],\n",
    "    system_prompt=\"You are a helpful assistant that can call multiple APIs. When asked to call APIs, call both API 1 and API 2.\"\n",
    ")\n",
    "\n",
    "result = agent(\"Can you call both of my APIs?\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Normal Agent invocation completed at: {time.strftime('%H:%M:%S.%f', time.localtime(end_time))[:-3]}\")\n",
    "print(f\"Normal Total execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501eecf",
   "metadata": {},
   "source": [
    "# Tool Context \n",
    "\n",
    "After setting the context=True in the decorator and adding ToolContex (which is __) to the tool definition, you have access to:\n",
    "- tool_use which has the name of the tool, a unique tool request id, and input parameters to the tool which can be any type.# \n",
    "- agent, which is the agent itself (and so you can reference its chat history and such )\n",
    "- and invocation_state caller provided key word arguments passed to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f23695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: get_self_name\n",
      "My name is **Best Model**. I'm here to assist you with any questions or tasks you might have!\n",
      "Tool #2: get_tool_use_id\n",
      "The tool use ID is **tooluse_et4FfRljQHmDTjvRV0fgUA**. \n",
      "\n",
      "If you need anything else or want to explore more functionality, just let me know!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/strands/agent/agent.py:413: UserWarning: `**kwargs` parameter is deprecating, use `invocation_state` instead.\n",
      "  async for event in events:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #3: get_invocation_state\n",
      "The current invocation state is: **You're the best agent ;)** \n",
      "\n",
      "I'm glad to hear that! If there's anything specific you'd like to discuss or any assistance you need, I'm here to help."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"The current invocation state is: **You're the best agent ;)** \\n\\nI'm glad to hear that! If there's anything specific you'd like to discuss or any assistance you need, I'm here to help.\"}]}, metrics=EventLoopMetrics(cycle_count=6, tool_metrics={'get_self_name': ToolMetrics(tool={'toolUseId': 'tooluse_fWeyRBs8QXm_tgj-4sOCqQ', 'name': 'get_self_name', 'input': {}}, call_count=1, success_count=1, error_count=0, total_time=0.0006520748138427734), 'get_tool_use_id': ToolMetrics(tool={'toolUseId': 'tooluse_et4FfRljQHmDTjvRV0fgUA', 'name': 'get_tool_use_id', 'input': {}}, call_count=1, success_count=1, error_count=0, total_time=0.0004971027374267578), 'get_invocation_state': ToolMetrics(tool={'toolUseId': 'tooluse_7X076oOURb6J7dj-fGjy1Q', 'name': 'get_invocation_state', 'input': {}}, call_count=1, success_count=1, error_count=0, total_time=0.0007617473602294922)}, cycle_durations=[0.625762939453125, 0.6156909465789795, 0.7388017177581787], agent_invocations=[AgentInvocation(cycles=[EventLoopCycleMetric(event_loop_cycle_id='40a6ba5b-03f2-4729-8992-b0cd96117e70', usage={'inputTokens': 945, 'outputTokens': 15, 'totalTokens': 960}), EventLoopCycleMetric(event_loop_cycle_id='5df70c94-8f01-4b54-81de-c7b1817bdf85', usage={'inputTokens': 991, 'outputTokens': 24, 'totalTokens': 1015})], usage={'inputTokens': 1936, 'outputTokens': 39, 'totalTokens': 1975}), AgentInvocation(cycles=[EventLoopCycleMetric(event_loop_cycle_id='13df351c-0d01-4856-829d-e35e0ba1aa22', usage={'inputTokens': 1024, 'outputTokens': 16, 'totalTokens': 1040}), EventLoopCycleMetric(event_loop_cycle_id='3d677415-14d5-46bc-b5d8-8e6ba86e0ef5', usage={'inputTokens': 1085, 'outputTokens': 43, 'totalTokens': 1128})], usage={'inputTokens': 2109, 'outputTokens': 59, 'totalTokens': 2168}), AgentInvocation(cycles=[EventLoopCycleMetric(event_loop_cycle_id='2a87e6ae-33d5-4fa9-9ed9-c8e0e5f4a2fc', usage={'inputTokens': 1136, 'outputTokens': 16, 'totalTokens': 1152}), EventLoopCycleMetric(event_loop_cycle_id='e0972b54-7dd0-463a-b921-c5ff707fb2d3', usage={'inputTokens': 1187, 'outputTokens': 40, 'totalTokens': 1227})], usage={'inputTokens': 2323, 'outputTokens': 56, 'totalTokens': 2379})], traces=[<strands.telemetry.metrics.Trace object at 0x110fb56d0>, <strands.telemetry.metrics.Trace object at 0x10d269370>, <strands.telemetry.metrics.Trace object at 0x110fb5b50>, <strands.telemetry.metrics.Trace object at 0x110fb5880>, <strands.telemetry.metrics.Trace object at 0x110fb6c00>, <strands.telemetry.metrics.Trace object at 0x10ffe1310>], accumulated_usage={'inputTokens': 6368, 'outputTokens': 154, 'totalTokens': 6522}, accumulated_metrics={'latencyMs': 3021}), state={}, interrupts=None, structured_output=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from strands import tool, Agent, ToolContext\n",
    "\n",
    "@tool(context=True)\n",
    "def get_self_name(tool_context: ToolContext) -> str:\n",
    "    return f\"The agent name is {tool_context.agent.name}\"\n",
    "\n",
    "@tool(context=True)\n",
    "def get_tool_use_id(tool_context: ToolContext) -> str:\n",
    "    return f\"Tool use is {tool_context.tool_use[\"toolUseId\"]}\"\n",
    "\n",
    "@tool(context=True)\n",
    "def get_invocation_state(tool_context: ToolContext) -> str:\n",
    "    return f\"Invocation state: {tool_context.invocation_state[\"custom_data\"]}\"\n",
    "\n",
    "agent = Agent(tools=[get_self_name, get_tool_use_id, get_invocation_state], name=\"Best agent\")\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[get_self_name, get_tool_use_id, get_invocation_state],\n",
    "    name='Best Model'\n",
    ")\n",
    "\n",
    "\n",
    "agent(\"What is your name?\")\n",
    "agent(\"What is the tool use id?\")\n",
    "agent(\"What is the invocation state?\", custom_data=\"You're the best agent ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5856248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: api_call\n",
      "got user id:  user123\n",
      "Here's your fake profile data based on the test request:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"fake_key\": \"fake_value\"\n",
      "}\n",
      "```\n",
      "\n",
      "This appears to be a simple test response with placeholder data. If you need more detailed fake profile information or have a specific data structure in mind, please let me know and I can help generate more comprehensive test data for your needs."
     ]
    }
   ],
   "source": [
    "### 'Invocation State' usage by passing key value pair in the chat\n",
    "\n",
    "from strands import tool, Agent, ToolContext\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def fake_api(user_id):\n",
    "    print('got user id: ', user_id)\n",
    "    return {'fake_key': 'fake_value'}\n",
    "\n",
    "@tool(context=True)\n",
    "def api_call(query: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Make an API call with user context.\n",
    "\n",
    "    Args:\n",
    "        query: The search query to send to the API\n",
    "        tool_context: Context containing user information\n",
    "    \"\"\"\n",
    "    user_id = tool_context.invocation_state.get(\"user_id\")\n",
    "\n",
    "    response = fake_api(user_id)\n",
    "\n",
    "    return response\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[api_call]\n",
    "    )\n",
    "\n",
    "# the docs example at the time of writing (user_id=\"user123\") is depracated\n",
    "result = agent(\"Get my fake profile data. This is a test.\", invocation_state={\"user_id\": \"user123\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca998d",
   "metadata": {},
   "source": [
    "## Module Based Usage \n",
    "\n",
    "by default files defining tools should go in the ./tools directory. \n",
    "\n",
    "You can also provide a direct path to the tool. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f18371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather_module', 'hello_test']\n"
     ]
    }
   ],
   "source": [
    "# this demonstrates loading a tool using the @tool decorator (hello_tool), and also one using TOOL_SPEC (weather_module)\n",
    "\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    load_tools_from_directory=True\n",
    "    )\n",
    "\n",
    "print(agent.tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b403a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolUseId': 'tooluse_hello_test_540414264',\n",
       " 'status': 'success',\n",
       " 'content': [{'text': 'Hello, Chris!'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tool.hello_test(name=\"Chris\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c331be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolUseId': 'tooluse_weather_module_415779546',\n",
       " 'status': 'success',\n",
       " 'content': [{'text': 'Weather forecast for  for the next 3 days...'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tool.weather_module(name=\"Chris\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b566a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello_test']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we can also load tools providing the file path to the toos directly\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"global.amazon.nova-2-lite-v1:0\",  \n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=['./tools/hello_tool.py']\n",
    "    )\n",
    "\n",
    "print(agent.tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b1cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolUseId': 'tooluse_hello_test_997023815',\n",
       " 'status': 'success',\n",
       " 'content': [{'text': 'Hello, Chris!'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.tool.hello_test(name=\"Chris\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
